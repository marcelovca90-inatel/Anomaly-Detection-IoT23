{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c77bf",
   "metadata": {},
   "source": [
    "### Execution parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b58014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "limit_rows = (1)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    return datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d2bb0",
   "metadata": {},
   "source": [
    "### Read individual data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28554b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = 'D:/Workspace/IoT-23 Dataset/iot_23_datasets_small/opt/Malware-Project/BigDataset/IoTScenarios/'\n",
    "sub_folders = filter(lambda x : ('Honeypot' not in x and 'bro' in x), [x[0] for x in os.walk(base_folder)])\n",
    "base_filename = 'conn.log.labeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "\n",
    "for folder in sub_folders:  \n",
    "    \n",
    "    full_filename = folder.replace('\\\\','/') + '/' + base_filename\n",
    "    \n",
    "    print(f\"{get_time()} Processing folder '{folder}' started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")\n",
    "    \n",
    "    df = pd.read_table(filepath_or_buffer=full_filename, skiprows=8, nrows=limit_rows)\n",
    "    \n",
    "    df.columns = [\n",
    "        'ts',\n",
    "        'uid',\n",
    "        'id.orig_h',\n",
    "        'id.orig_p',\n",
    "        'id.resp_h',\n",
    "        'id.resp_p',\n",
    "        'proto',\n",
    "        'service',\n",
    "        'duration',\n",
    "        'orig_bytes',\n",
    "        'resp_bytes',\n",
    "        'conn_state',\n",
    "        'local_orig',\n",
    "        'local_resp',\n",
    "        'missed_bytes',\n",
    "        'history',\n",
    "        'orig_pkts',\n",
    "        'orig_ip_bytes',\n",
    "        'resp_pkts',\n",
    "        'resp_ip_bytes',\n",
    "        'label'\n",
    "    ]\n",
    "    \n",
    "    df.drop(columns=['ts','uid','service','local_orig','local_resp','history','id.orig_h','id.resp_h'], inplace=True)\n",
    "        \n",
    "    df.drop(df.tail(1).index, inplace=True)\n",
    "    \n",
    "    print(f'{get_time()} Duplicated rows (before removal):\\t{df.duplicated().sum()}')\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f'{get_time()} Duplicated rows (after removal):\\t{df.duplicated().sum()}')\n",
    "    \n",
    "    data_frames.append(df)\n",
    "        \n",
    "    print(f\"{get_time()} Processing finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}; DF shape: {df.shape}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac18282",
   "metadata": {},
   "source": [
    "### Concatenate data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.concat(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-valley",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ee33a",
   "metadata": {},
   "source": [
    "### Standardize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-buffer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_c['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44535982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_label(src,dest):\n",
    "    df_c.loc[(df_c.label == src), 'label'] = dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_label('-   Malicious   Attack',                                  'Attack')\n",
    "replace_label('(empty)   Malicious   Attack',                            'Attack')\n",
    "replace_label('-   Benign   -',                                          'Benign')\n",
    "replace_label('(empty)   Benign   -',                                    'Benign')\n",
    "replace_label('COLnd035cNITygYHp3   Benign   -',                         'Benign')\n",
    "replace_label('-   Malicious   C&C',                                     'C&C')\n",
    "replace_label('(empty)   Malicious   C&C',                               'C&C')\n",
    "replace_label('-   Malicious   C&C-FileDownload',                        'C&C-FileDownload')\n",
    "replace_label('-   Malicious   C&C-HeartBeat',                           'C&C-HeartBeat')\n",
    "replace_label('(empty)   Malicious   C&C-HeartBeat',                     'C&C-HeartBeat')\n",
    "replace_label('-   Malicious   C&C-HeartBeat-Attack',                    'C&C-HeartBeat-Attack')\n",
    "replace_label('-   Malicious   C&C-HeartBeat-FileDownload',              'C&C-HeartBeat-FileDownload')\n",
    "replace_label('-   Malicious   C&C-HeartBeat-PartOfAHorizontalPortScan', 'C&C-HeartBeat-PartOfAHorizontalPortScan')\n",
    "replace_label('-   Malicious   C&C-Mirai',                               'C&C-Mirai')\n",
    "replace_label('-   Malicious   C&C-PartOfAHorizontalPortScan',           'C&C-PartOfAHorizontalPortScan')\n",
    "replace_label('-   Malicious   C&C-Torii',                               'C&C-Torii')\n",
    "replace_label('-   Malicious   DDoS',                                    'DDoS')\n",
    "replace_label('(empty)   Malicious   DDoS',                              'DDoS')\n",
    "replace_label('-   Malicious   FileDownload',                            'FileDownload')\n",
    "replace_label('-   Malicious   Okiru',                                   'Okiru')\n",
    "replace_label('(empty)   Malicious   Okiru',                             'Okiru')\n",
    "replace_label('-   Malicious   Okiru-Attack',                            'Okiru-Attack')\n",
    "replace_label('-   Malicious   PartOfAHorizontalPortScan',               'PartOfAHorizontalPortScan')\n",
    "replace_label('(empty)   Malicious   PartOfAHorizontalPortScan',         'PartOfAHorizontalPortScan')\n",
    "replace_label('-   Malicious   PartOfAHorizontalPortScan-Attack',        'PartOfAHorizontalPortScan-Attack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-might",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_c['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448be8f",
   "metadata": {},
   "source": [
    "### Remove less frequent classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8933ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = df_c['label'].value_counts(normalize=True)\n",
    "print(f'**** Value counts (before) ****\\n{vc}')\n",
    "threshold = vc.quantile(0.75)\n",
    "print(f'\\n**** Dropping rows with less than {threshold:g} occurrences ****\\n')\n",
    "df_c = df_c[df_c['label'].isin(vc.index[vc.gt(threshold)])]\n",
    "vc = df_c['label'].value_counts(normalize=True)\n",
    "print(f'**** Value counts (after) ****\\n{vc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc02053",
   "metadata": {},
   "source": [
    "### Replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.loc[(df_c.duration == '-'), 'duration'] = 0.0\n",
    "df_c.loc[(df_c.orig_bytes == '-'), 'orig_bytes'] = 0\n",
    "df_c.loc[(df_c.resp_bytes == '-'), 'resp_bytes'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6143649",
   "metadata": {},
   "source": [
    "### Remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NaN values (before removal):','\\n',df_c.isna().sum())\n",
    "df_c = df_c.dropna()\n",
    "print('\\nNaN values (after removal):','\\n',df_c.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6afb2a7",
   "metadata": {},
   "source": [
    "### Remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81e637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_cols = [x for x in df_c.columns]\n",
    "print('Duplicated rows (before removal):\\t',df_c.duplicated().sum())\n",
    "df_c['count'] = 1\n",
    "df_c = df_c.groupby(current_cols)['count'].count().reset_index().drop_duplicates()\n",
    "print('Duplicated rows (after removal):\\t',df_c.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af12729a",
   "metadata": {},
   "source": [
    "### One-hot-encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_encoded = ['proto','conn_state']#,'id.orig_p','id.resp_p']\n",
    "for col in to_be_encoded:\n",
    "    df_c = pd.get_dummies(df_c, columns=[col])\n",
    "    print(f'Column \\'{col}\\' successfully one-hot-encoded; new DF shape: {df_c.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93519e4",
   "metadata": {},
   "source": [
    "### Reorder columns to [..., count, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477bc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = [x for x in df_c.columns.values if x != 'label' and x != 'count']\n",
    "final_cols.append('count')\n",
    "final_cols.append('label')\n",
    "print(final_cols,type(final_cols))\n",
    "df_c = df_c.reindex(columns=final_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732dc538",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Define data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b7afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.astype({\n",
    "    'id.orig_p'     : 'uint64',\n",
    "    'id.resp_p'     : 'uint64',\n",
    "    'duration'      : float,\n",
    "    'orig_bytes'    : 'uint64',\n",
    "    'resp_bytes'    : 'uint64',\n",
    "    'missed_bytes'  : 'uint64',\n",
    "    'orig_pkts'     : 'uint64',\n",
    "    'orig_ip_bytes' : 'uint64',\n",
    "    'resp_pkts'     : 'uint64',\n",
    "    'resp_ip_bytes' : 'uint64',\n",
    "    'label'         : 'category'\n",
    "}).infer_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43133a04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(json.dumps(dict(df_c.dtypes), indent=4, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0398f5",
   "metadata": {},
   "source": [
    "### Split data intro train/test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f20ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_c.drop(labels=['label'], axis=1),\n",
    "                                                    df_c['label'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3579a13",
   "metadata": {},
   "source": [
    "### Select relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3dc9fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "constant_filter = VarianceThreshold(threshold=0.01)\n",
    "constant_filter.fit(X_train)\n",
    "\n",
    "print('\\nNon quasi-constant columns:')\n",
    "non_constant_columns = [column for column in X_train.columns if column not in X_train.columns[constant_filter.get_support()]]\n",
    "print(non_constant_columns)\n",
    "\n",
    "print('\\nQuasi-constant columns:')\n",
    "constant_columns = [column for column in X_train.columns if column in X_train.columns[constant_filter.get_support()]]\n",
    "print(constant_columns)\n",
    "\n",
    "X_train = constant_filter.transform(X_train)\n",
    "X_test = constant_filter.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a9402",
   "metadata": {},
   "source": [
    "### Scale data to [0,1] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708fd74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "range_scaler = MinMaxScaler()\n",
    "range_scaler.fit(X_train)\n",
    "\n",
    "X_train = range_scaler.transform(X_train)\n",
    "X_test = range_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c710d4a6",
   "metadata": {},
   "source": [
    "### Persist train and test data subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6734cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_csv(df,name):\n",
    "    if limit_rows is None:        \n",
    "        pd.DataFrame(df).to_csv(f'sklearn/iot23_combined_{name}.csv',\n",
    "                                float_format='%g',\n",
    "                                header=None,\n",
    "                                index=None)\n",
    "    else:\n",
    "        pd.DataFrame(df).round(6).to_csv(f'sklearn/iot23_combined_{int(limit_rows/1000)}k_{name}.csv',\n",
    "                                float_format='%g',\n",
    "                                header=None,\n",
    "                                index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff20c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_csv(X_train,'X_train')\n",
    "persist_csv(y_train,'y_train')\n",
    "print('X_train',X_train.shape,'\\ny_train',y_train.shape)\n",
    "\n",
    "persist_csv(X_test,'X_test')\n",
    "persist_csv(y_test,'y_test')\n",
    "print('X_test',X_test.shape,'\\ny_test',y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

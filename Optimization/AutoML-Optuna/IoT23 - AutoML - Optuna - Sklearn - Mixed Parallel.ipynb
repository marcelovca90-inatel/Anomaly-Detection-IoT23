{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kd-Bm8brf0Fz",
   "metadata": {
    "id": "Kd-Bm8brf0Fz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import plotly\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import sklearn\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "limit_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc175db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Execution started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(name):\n",
    "    if limit_rows is None:\n",
    "        full_filename = f'../Data Preprocessing/sklearn/full/iot23_combined_{name}.csv'\n",
    "    else:\n",
    "        full_filename = f'../Data Preprocessing/sklearn/partial/iot23_combined_{int(limit_rows/1000)}k_{name}.csv'\n",
    "    \n",
    "    df = pd.read_table(filepath_or_buffer=full_filename, header=None, sep=',').infer_objects().to_numpy()\n",
    "    \n",
    "    return df.ravel() if df.shape[1] == 1 else df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-hotel",
   "metadata": {
    "id": "steady-hotel",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_csv('X_train'), load_csv('X_test'), load_csv('y_train'), load_csv('y_test')\n",
    "\n",
    "print('X_train',X_train.shape,'\\ny_train',y_train.shape)\n",
    "print('X_test',X_test.shape,'\\ny_test',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "\n",
    "'''\n",
    "def print_trial_callback(study,trial):\n",
    "    try:\n",
    "        print(f\"[{str(trial.number).rjust(6,'0')}] {str(trial.state).ljust(20)}\\tScore = {str(np.round(trial.values[0],9)).ljust(12,'0')}\\tClassifier = {trial.params['classifier_name']}\\n\")\n",
    "    except:\n",
    "        print(f\"[{str(trial.number).rjust(6,'0')}] {str(trial.state).ljust(20)}\\tScore = {str(np.round(float('nan'))).ljust(12,' ')}\\tClassifier = {trial.params['classifier_name']}\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Optimization started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f06faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron\n",
    "from sklearn.naive_bayes import ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_results = {}\n",
    "\n",
    "classifier_names = [\n",
    "    'AdaBoostClassifier',\n",
    "    'ComplementNB',\n",
    "    'DecisionTreeClassifier',\n",
    "    'ExtraTreesClassifier',\n",
    "    'GaussianNB',\n",
    "    'GaussianProcessClassifier',\n",
    "    'KNeighborsClassifier',\n",
    "    'LinearDiscriminantAnalysis',\n",
    "    'LinearSVC',\n",
    "    'MLPClassifier',\n",
    "    'MultinomialNB',\n",
    "    'NystroemLinearSVC',\n",
    "    'PassiveAggressiveClassifier',\n",
    "    'QuadraticDiscriminantAnalysis',\n",
    "    'RandomForestClassifier',\n",
    "    'XGBClassifier'\n",
    "]\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    classifier_name = trial.suggest_categorical('classifier_name', classifier_names)\n",
    "\n",
    "    if classifier_name      == 'AdaBoostClassifier':\n",
    "        n_estimators         = trial.suggest_int('abc_n_estimators', 10, 200, 10)\n",
    "        learning_rate        = trial.suggest_loguniform('abc_learning_rate', 1e-6, 1e0)\n",
    "        classifier_obj       = AdaBoostClassifier(n_estimators=n_estimators,learning_rate=learning_rate)\n",
    "\n",
    "    elif classifier_name    == 'ComplementNB':\n",
    "        alpha                = trial.suggest_discrete_uniform('cnb_alpha', 0.1, 1.0, 0.1)\n",
    "        fit_prior            = trial.suggest_categorical('cnb_fit_prior', [False, True])\n",
    "        norm                 = trial.suggest_categorical('cnb_norm', [False, True])\n",
    "        classifier_obj       = ComplementNB(alpha=alpha,fit_prior=fit_prior,norm=norm)\n",
    "\n",
    "    elif classifier_name    == 'DecisionTreeClassifier':\n",
    "        criterion            = trial.suggest_categorical('dtc_criterion', ['gini', 'entropy'])\n",
    "        splitter             = trial.suggest_categorical('dtc_splitter', ['best', 'random'])\n",
    "        min_samples_split    = trial.suggest_int('dtc_min_samples_split', 2, 50)\n",
    "        min_samples_leaf     = trial.suggest_int('dtc_min_samples_leaf', 1, 50)\n",
    "        max_features         = trial.suggest_int('dtc_max_features', 1, X_train.shape[1])\n",
    "        classifier_obj       = DecisionTreeClassifier(criterion=criterion, \n",
    "                                                      splitter=splitter, \n",
    "                                                      min_samples_split=min_samples_split,\n",
    "                                                      min_samples_leaf=min_samples_leaf,\n",
    "                                                      max_features=max_features)\n",
    "\n",
    "    elif classifier_name    == 'ExtraTreesClassifier':\n",
    "        n_estimators         = trial.suggest_int('etc_n_estimators', 10, 200, 10)\n",
    "        criterion            = trial.suggest_categorical('etc_criterion', ['gini', 'entropy'])\n",
    "        min_samples_split    = trial.suggest_int('etc_min_samples_split', 2, 50)\n",
    "        min_samples_leaf     = trial.suggest_int('etc_min_samples_leaf', 1, 50)\n",
    "        max_features         = trial.suggest_int('etc_max_features', 1, X_train.shape[1])\n",
    "        bootstrap            = trial.suggest_categorical('etc_bootstrap', [False, True])\n",
    "        classifier_obj       = ExtraTreesClassifier(n_estimators=n_estimators,\n",
    "                                                    criterion=criterion, \n",
    "                                                    min_samples_split=min_samples_split,\n",
    "                                                    min_samples_leaf=min_samples_leaf,\n",
    "                                                    max_features=max_features,\n",
    "                                                    bootstrap=bootstrap)\n",
    "\n",
    "    elif classifier_name    == 'GaussianNB':\n",
    "        var_smoothing        = trial.suggest_loguniform('gnb_var_smoothing', 1e-12, 1e0)\n",
    "        classifier_obj       = GaussianNB(var_smoothing=var_smoothing)\n",
    "\n",
    "    elif classifier_name    == 'GaussianProcessClassifier':\n",
    "        max_iter_predict     = trial.suggest_int('gpc_max_iter_predict', 50, 200, 50)\n",
    "        multi_class          = trial.suggest_categorical('gpc_multi_class', ['one_vs_one', 'one_vs_rest'])\n",
    "        classifier_obj       = GaussianProcessClassifier(max_iter_predict=max_iter_predict,\n",
    "                                                         multi_class=multi_class)\n",
    "\n",
    "    elif classifier_name    == 'KNeighborsClassifier':\n",
    "        n_neighbors          = trial.suggest_int('knc_n_neighbors', 10, 100, 10)\n",
    "        leaf_size            = trial.suggest_int('knc_leaf_size', 10, 100, 10)\n",
    "        classifier_obj       = KNeighborsClassifier(n_neighbors=n_neighbors,leaf_size=leaf_size)\n",
    "\n",
    "    elif classifier_name    == 'LinearDiscriminantAnalysis':\n",
    "        n_features,n_classes = X_train.shape[1],len(set(y_train))\n",
    "        n_components         = trial.suggest_int('lda_n_components', 1, min(n_features, n_classes-1))\n",
    "        classifier_obj       = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "\n",
    "    elif classifier_name    == 'LinearSVC':\n",
    "        dual                 = trial.suggest_categorical('lsvc_dual', [False])\n",
    "        C                    = trial.suggest_loguniform('lsvc_C', 1e-6, 1e3)\n",
    "        classifier_obj       = LinearSVC(dual=dual,C=C)\n",
    "\n",
    "    elif classifier_name    == 'MLPClassifier':\n",
    "        create_hidden_layers = lambda value,count : tuple([int(value*2**(count-i-1)) for i in range(0,count)])\n",
    "        hidden_layer_count   = trial.suggest_int('mlpc_hidden_layer_count', 1, 3, 1)\n",
    "        hidden_layer_sizes   = create_hidden_layers(2*X_train.shape[1], hidden_layer_count)\n",
    "        learning_rate        = trial.suggest_categorical('mlpc_learning_rate', ['constant', 'invscaling', 'adaptive'])\n",
    "        learning_rate_init   = trial.suggest_loguniform('mlpc_learning_rate_init', 1e-6, 1e0)\n",
    "        max_iter             = trial.suggest_int('mplc_max_iter', 250, 1000, 250)\n",
    "        classifier_obj       = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                             learning_rate=learning_rate,\n",
    "                                             learning_rate_init=learning_rate_init,\n",
    "                                             max_iter=max_iter)\n",
    "\n",
    "    elif classifier_name    == 'MultinomialNB':\n",
    "        alpha                = trial.suggest_discrete_uniform('mnb_alpha', 0.1, 1.0, 0.1)\n",
    "        fit_prior            = trial.suggest_categorical('mnb_fit_prior', [False, True])\n",
    "        classifier_obj       = MultinomialNB(alpha=alpha,fit_prior=fit_prior)\n",
    "\n",
    "    elif classifier_name    == 'NystroemLinearSVC':\n",
    "        approx_gamma         = trial.suggest_discrete_uniform(\"nystroem_gamma\", 0.1, 1.0, 0.1)\n",
    "        approx_n_components  = trial.suggest_int(\"nystroem_n_components\", 50, 200, 25)            \n",
    "        dual                 = trial.suggest_categorical('dual', [False])\n",
    "        C                    = trial.suggest_loguniform('C', 1e-6, 1e3)\n",
    "\n",
    "        classifier_obj = LinearSVC(dual=dual,C=C)\n",
    "\n",
    "\n",
    "    elif classifier_name    == 'PassiveAggressiveClassifier':\n",
    "        C                    = trial.suggest_loguniform('pac_C', 1e-6, 1e3)\n",
    "        early_stopping       = trial.suggest_categorical('pac_early_stopping', [False, True])\n",
    "        validation_fraction  = trial.suggest_categorical('pac_validation_fraction', [0.25])\n",
    "        n_iter_no_change     = trial.suggest_int('pac_n_iter_no_change', 5, 20, 5)\n",
    "        classifier_obj       = PassiveAggressiveClassifier(C=C,\n",
    "                                                           early_stopping=early_stopping,\n",
    "                                                           validation_fraction=validation_fraction,\n",
    "                                                           n_iter_no_change=n_iter_no_change)\n",
    "\n",
    "    elif classifier_name    == 'Perceptron':\n",
    "        penalty              = trial.suggest_categorical('p_penalty', ['l2,', 'l1', 'elasticnet'])\n",
    "        alpha                = trial.suggest_discrete_uniform('p_alpha', 0.1, 1.0, 0.1)\n",
    "        eta0                 = trial.suggest_discrete_uniform('p_eta0', 0.5, 2.0, 0.5)\n",
    "        early_stopping       = trial.suggest_categorical('p_early_stopping', [False, True])\n",
    "        validation_fraction  = trial.suggest_categorical('p_validation_fraction', [0.25])\n",
    "        n_iter_no_change     = trial.suggest_int('p_n_iter_no_change', 5, 20, 5)\n",
    "        classifier_obj       = Perceptron(penalty=penalty,\n",
    "                                          alpha=alpha,\n",
    "                                          eta0=eta0,\n",
    "                                          early_stopping=early_stopping,\n",
    "                                          n_iter_no_change=n_iter_no_change)\n",
    "\n",
    "    elif classifier_name    == 'QuadraticDiscriminantAnalysis':\n",
    "        reg_param            = trial.suggest_discrete_uniform('qda_reg_param', 0.1, 1.0, 0.1)\n",
    "        classifier_obj       = QuadraticDiscriminantAnalysis(reg_param=reg_param)\n",
    "\n",
    "    elif classifier_name    == 'RandomForestClassifier':\n",
    "        n_estimators         = trial.suggest_int('rfc_n_estimators', 10, 200, 10)\n",
    "        criterion            = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        min_samples_split    = trial.suggest_int('rfc_min_samples_split', 2, 50)\n",
    "        min_samples_leaf     = trial.suggest_int('rfc_min_samples_leaf', 1, 50)\n",
    "        max_features         = trial.suggest_int('rfc_max_features', 1, X_train.shape[1])\n",
    "        bootstrap            = trial.suggest_categorical('rfc_bootstrap', [False, True])\n",
    "        classifier_obj       = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                                      criterion=criterion, \n",
    "                                                      min_samples_split=min_samples_split,\n",
    "                                                      min_samples_leaf=min_samples_leaf,\n",
    "                                                      max_features=max_features,\n",
    "                                                      bootstrap=bootstrap)\n",
    "    else: # classifier_name == 'XGBClassifier'\n",
    "        n_estimators         = trial.suggest_int('xgbc_n_estimators', 10, 200, 10)\n",
    "        use_label_encoder    = trial.suggest_categorical('xgbc_use_label_encoder', [False])\n",
    "        learning_rate        = trial.suggest_loguniform('xgbc_learning_rate', 1e-6, 1e0)\n",
    "        booster              = trial.suggest_categorical('xgbc_booster', ['gbtree', 'gblinear', 'dart'])\n",
    "        gamma                = trial.suggest_loguniform('xgbc_gamma', 1e-6, 1e0)\n",
    "        classifier_obj       = XGBClassifier(n_estimators=n_estimators, \n",
    "                                             use_label_encoder=use_label_encoder,\n",
    "                                             learning_rate=learning_rate,\n",
    "                                             booster=booster,\n",
    "                                             gamma=gamma)\n",
    "        \n",
    "    # fit, predict and evaluate\n",
    "    if classifier_name == 'NystroemLinearSVC':\n",
    "        feature_mapper = Nystroem(gamma=approx_gamma,n_components=approx_n_components).fit(X_train)\n",
    "        classifier_obj.fit(feature_mapper.transform(X_train), y_train)\n",
    "        y_pred = classifier_obj.predict(feature_mapper.transform(X_test))\n",
    "    else:\n",
    "        classifier_obj.fit(X_train, y_train)\n",
    "        y_pred = classifier_obj.predict(X_test)\n",
    "\n",
    "    return sklearn.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed129e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Optimization started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "#study.optimize(objective, n_trials=n_cpus-1, n_jobs=n_cpus-1, catch=(ValueError,))\n",
    "#study.optimize(objective, timeout=60*60*len(classifier_names)/2, n_jobs=n_cpus, catch=(ValueError,))\n",
    "study.optimize(objective, n_trials=4*len(classifier_names), n_jobs=8, catch=(ValueError,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a73c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Optimization finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each classifier, sort results according to score (descending)\n",
    "best_results = dict(sorted(best_results.items()))\n",
    "for key,value in best_results.items():\n",
    "    best_results[key] = sorted(best_results[key], key=lambda d: d['score'], reverse=True) \n",
    "\n",
    "# print the best results found for each classifier\n",
    "for key,value in best_results.items():\n",
    "    print(key,json.dumps(value[0], indent=4, default=str))\n",
    "\n",
    "# persist results to filesystem    \n",
    "with open('IoT23 - AutoML - Optuna - Sklearn - Mixed Parallel.json', 'w') as fp:\n",
    "    json.dump(best_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b44949",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "idx = 0\n",
    "for key, value in best_results.items():\n",
    "    name_i = key\n",
    "    value_i = best_results[key][0]['score']\n",
    "    plt.bar(name_i,value_i)\n",
    "    plt.text(idx-0.1,value_i+0.01,f'{100*value_i:.1f}%')\n",
    "    idx += 1\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xticks(range(0,len(best_results)),best_results.keys())\n",
    "plt.yticks(np.linspace(0,1,11))\n",
    "plt.ylim(0,1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab29c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Execution finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "IoT23 - DNN Opt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Kd-Bm8brf0Fz",
   "metadata": {
    "id": "Kd-Bm8brf0Fz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "C:\\Users\\marce\\Anaconda2\\envs\\doutorado\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from hpsklearn import *\n",
    "from hyperopt import hp, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2229336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc175db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution started at 2022-02-22 03:08:11.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "better-permit",
   "metadata": {
    "id": "better-permit"
   },
   "outputs": [],
   "source": [
    "filepath = \"../Data Preprocessing/iot23_combined_100k.csv\"\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial-biotechnology",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "initial-biotechnology",
    "outputId": "e027dfbe-1202-4a40-d0d4-fdbb083049ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>conn_state_RSTOS0</th>\n",
       "      <th>conn_state_RSTR</th>\n",
       "      <th>conn_state_RSTRH</th>\n",
       "      <th>conn_state_S0</th>\n",
       "      <th>conn_state_S1</th>\n",
       "      <th>conn_state_S2</th>\n",
       "      <th>conn_state_S3</th>\n",
       "      <th>conn_state_SF</th>\n",
       "      <th>conn_state_SH</th>\n",
       "      <th>conn_state_SHR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.998796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.998804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444669</th>\n",
       "      <td>99994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444670</th>\n",
       "      <td>99995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444671</th>\n",
       "      <td>99996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444672</th>\n",
       "      <td>99997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444673</th>\n",
       "      <td>99998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PartOfAHorizontalPortScan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444674 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  duration  orig_bytes  resp_bytes  missed_bytes  \\\n",
       "0                 0  2.998796           0           0           0.0   \n",
       "1                 1  0.000000           0           0           0.0   \n",
       "2                 2  0.000000           0           0           0.0   \n",
       "3                 3  2.998804           0           0           0.0   \n",
       "4                 4  0.000000           0           0           0.0   \n",
       "...             ...       ...         ...         ...           ...   \n",
       "1444669       99994  0.000000           0           0           0.0   \n",
       "1444670       99995  0.000000           0           0           0.0   \n",
       "1444671       99996  0.000000           0           0           0.0   \n",
       "1444672       99997  0.000000           0           0           0.0   \n",
       "1444673       99998  0.000000           0           0           0.0   \n",
       "\n",
       "         orig_pkts  orig_ip_bytes  resp_pkts  resp_ip_bytes  \\\n",
       "0              3.0          180.0        0.0            0.0   \n",
       "1              1.0           60.0        0.0            0.0   \n",
       "2              1.0           60.0        0.0            0.0   \n",
       "3              3.0          180.0        0.0            0.0   \n",
       "4              1.0           60.0        0.0            0.0   \n",
       "...            ...            ...        ...            ...   \n",
       "1444669        1.0           40.0        0.0            0.0   \n",
       "1444670        1.0           40.0        0.0            0.0   \n",
       "1444671        1.0           40.0        0.0            0.0   \n",
       "1444672        1.0           40.0        0.0            0.0   \n",
       "1444673        1.0           40.0        0.0            0.0   \n",
       "\n",
       "                             label  ...  conn_state_RSTOS0  conn_state_RSTR  \\\n",
       "0        PartOfAHorizontalPortScan  ...                  0                0   \n",
       "1        PartOfAHorizontalPortScan  ...                  0                0   \n",
       "2        PartOfAHorizontalPortScan  ...                  0                0   \n",
       "3                           Benign  ...                  0                0   \n",
       "4                           Benign  ...                  0                0   \n",
       "...                            ...  ...                ...              ...   \n",
       "1444669  PartOfAHorizontalPortScan  ...                  0                0   \n",
       "1444670  PartOfAHorizontalPortScan  ...                  0                0   \n",
       "1444671  PartOfAHorizontalPortScan  ...                  0                0   \n",
       "1444672  PartOfAHorizontalPortScan  ...                  0                0   \n",
       "1444673  PartOfAHorizontalPortScan  ...                  0                0   \n",
       "\n",
       "         conn_state_RSTRH  conn_state_S0  conn_state_S1  conn_state_S2  \\\n",
       "0                       0              1              0              0   \n",
       "1                       0              1              0              0   \n",
       "2                       0              1              0              0   \n",
       "3                       0              1              0              0   \n",
       "4                       0              1              0              0   \n",
       "...                   ...            ...            ...            ...   \n",
       "1444669                 0              1              0              0   \n",
       "1444670                 0              1              0              0   \n",
       "1444671                 0              1              0              0   \n",
       "1444672                 0              1              0              0   \n",
       "1444673                 0              1              0              0   \n",
       "\n",
       "         conn_state_S3  conn_state_SF  conn_state_SH  conn_state_SHR  \n",
       "0                    0              0              0               0  \n",
       "1                    0              0              0               0  \n",
       "2                    0              0              0               0  \n",
       "3                    0              0              0               0  \n",
       "4                    0              0              0               0  \n",
       "...                ...            ...            ...             ...  \n",
       "1444669              0              0              0               0  \n",
       "1444670              0              0              0               0  \n",
       "1444671              0              0              0               0  \n",
       "1444672              0              0              0               0  \n",
       "1444673              0              0              0               0  \n",
       "\n",
       "[1444674 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "paperback-heritage",
   "metadata": {
    "id": "paperback-heritage"
   },
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inside-north",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inside-north",
    "outputId": "e2ccfd8b-0e5b-486d-ee29-432dbeeddad2",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartOfAHorizontalPortScan     825939\n",
       "Okiru                         262690\n",
       "Benign                        197809\n",
       "DDoS                          138777\n",
       "C&C                            15100\n",
       "Attack                          3915\n",
       "C&C-HeartBeat                    349\n",
       "C&C-FileDownload                  43\n",
       "C&C-Torii                         30\n",
       "FileDownload                      13\n",
       "C&C-HeartBeat-FileDownload         8\n",
       "C&C-Mirai                          1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7654c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Okiru', 'DDoS', 'C&C', 'Attack', 'C&C-HeartBeat', 'C&C-FileDownload',\n",
      "       'C&C-Torii', 'FileDownload', 'C&C-HeartBeat-FileDownload', 'C&C-Mirai'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PartOfAHorizontalPortScan    825939\n",
       "Benign                       197809\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good = 'Benign'\n",
    "bad = 'PartOfAHorizontalPortScan'\n",
    "filtered_labels = df['label'].value_counts().index.drop([good,bad])\n",
    "for label in filtered_labels:\n",
    "    df.drop(df[df.label == label].index, inplace=True) \n",
    "print(filtered_labels)\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f100df72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    825939\n",
       "0    197809\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.label == good), 'label'] = 0\n",
    "df.loc[(df.label == bad), 'label'] = 1\n",
    "df = df.astype({'label': int})\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "893a0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for label in df['label'].value_counts().index:\n",
    "#    if rank < 3:\n",
    "#        df.loc[(df.label == label), 'label'] = rank\n",
    "#    else:\n",
    "#        df.drop(df[df.label == label].index, inplace=True) \n",
    "#    rank += 1\n",
    "#df = df.astype({'label': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "steady-hotel",
   "metadata": {
    "id": "steady-hotel"
   },
   "outputs": [],
   "source": [
    "X = df[['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "published-store",
   "metadata": {
    "id": "published-store"
   },
   "outputs": [],
   "source": [
    "Y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "green-schema",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "green-schema",
    "outputId": "b4b07e01-9bb8-4483-ea97-ffca33a201c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>label</th>\n",
       "      <th>proto_icmp</th>\n",
       "      <th>...</th>\n",
       "      <th>conn_state_RSTOS0</th>\n",
       "      <th>conn_state_RSTR</th>\n",
       "      <th>conn_state_RSTRH</th>\n",
       "      <th>conn_state_S0</th>\n",
       "      <th>conn_state_S1</th>\n",
       "      <th>conn_state_S2</th>\n",
       "      <th>conn_state_S3</th>\n",
       "      <th>conn_state_SF</th>\n",
       "      <th>conn_state_SH</th>\n",
       "      <th>conn_state_SHR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.998796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.998804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444669</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444670</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444671</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444672</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444673</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023748 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         duration  orig_bytes  resp_bytes  missed_bytes  orig_pkts  \\\n",
       "0        2.998796           0           0           0.0        3.0   \n",
       "1        0.000000           0           0           0.0        1.0   \n",
       "2        0.000000           0           0           0.0        1.0   \n",
       "3        2.998804           0           0           0.0        3.0   \n",
       "4        0.000000           0           0           0.0        1.0   \n",
       "...           ...         ...         ...           ...        ...   \n",
       "1444669  0.000000           0           0           0.0        1.0   \n",
       "1444670  0.000000           0           0           0.0        1.0   \n",
       "1444671  0.000000           0           0           0.0        1.0   \n",
       "1444672  0.000000           0           0           0.0        1.0   \n",
       "1444673  0.000000           0           0           0.0        1.0   \n",
       "\n",
       "         orig_ip_bytes  resp_pkts  resp_ip_bytes  label  proto_icmp  ...  \\\n",
       "0                180.0        0.0            0.0      1           0  ...   \n",
       "1                 60.0        0.0            0.0      1           0  ...   \n",
       "2                 60.0        0.0            0.0      1           0  ...   \n",
       "3                180.0        0.0            0.0      0           0  ...   \n",
       "4                 60.0        0.0            0.0      0           0  ...   \n",
       "...                ...        ...            ...    ...         ...  ...   \n",
       "1444669           40.0        0.0            0.0      1           0  ...   \n",
       "1444670           40.0        0.0            0.0      1           0  ...   \n",
       "1444671           40.0        0.0            0.0      1           0  ...   \n",
       "1444672           40.0        0.0            0.0      1           0  ...   \n",
       "1444673           40.0        0.0            0.0      1           0  ...   \n",
       "\n",
       "         conn_state_RSTOS0  conn_state_RSTR  conn_state_RSTRH  conn_state_S0  \\\n",
       "0                        0                0                 0              1   \n",
       "1                        0                0                 0              1   \n",
       "2                        0                0                 0              1   \n",
       "3                        0                0                 0              1   \n",
       "4                        0                0                 0              1   \n",
       "...                    ...              ...               ...            ...   \n",
       "1444669                  0                0                 0              1   \n",
       "1444670                  0                0                 0              1   \n",
       "1444671                  0                0                 0              1   \n",
       "1444672                  0                0                 0              1   \n",
       "1444673                  0                0                 0              1   \n",
       "\n",
       "         conn_state_S1  conn_state_S2  conn_state_S3  conn_state_SF  \\\n",
       "0                    0              0              0              0   \n",
       "1                    0              0              0              0   \n",
       "2                    0              0              0              0   \n",
       "3                    0              0              0              0   \n",
       "4                    0              0              0              0   \n",
       "...                ...            ...            ...            ...   \n",
       "1444669              0              0              0              0   \n",
       "1444670              0              0              0              0   \n",
       "1444671              0              0              0              0   \n",
       "1444672              0              0              0              0   \n",
       "1444673              0              0              0              0   \n",
       "\n",
       "         conn_state_SH  conn_state_SHR  \n",
       "0                    0               0  \n",
       "1                    0               0  \n",
       "2                    0               0  \n",
       "3                    0               0  \n",
       "4                    0               0  \n",
       "...                ...             ...  \n",
       "1444669              0               0  \n",
       "1444670              0               0  \n",
       "1444671              0               0  \n",
       "1444672              0               0  \n",
       "1444673              0               0  \n",
       "\n",
       "[1023748 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "touched-tanzania",
   "metadata": {
    "id": "touched-tanzania"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=SEED, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "earned-advertiser",
   "metadata": {
    "id": "earned-advertiser"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************** AB ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:19<00:00, 19.54s/trial, best loss: 0.08752136752136752]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:10<00:00, 10.89s/trial, best loss: 0.08752136752136752]\n",
      "100%|████████████████████████████████████████████████| 3/3 [02:06<00:00, 126.02s/trial, best loss: 0.08752136752136752]\n",
      "100%|████████████████████████████████████████████████| 4/4 [04:17<00:00, 257.59s/trial, best loss: 0.08752136752136752]\n",
      "100%|████████████████████████████████████████████████| 5/5 [04:23<00:00, 263.98s/trial, best loss: 0.08752136752136752]\n",
      "100%|█████████████████████████████████████████████████| 6/6 [01:33<00:00, 93.77s/trial, best loss: 0.08752136752136752]\n",
      "100%|████████████████████████████████████████████████| 7/7 [02:22<00:00, 142.08s/trial, best loss: 0.08752136752136752]\n",
      "100%|█████████████████████████████████████████████████| 8/8 [00:22<00:00, 22.35s/trial, best loss: 0.08752136752136752]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:07<00:00,  7.88s/trial, best loss: 0.08752136752136752]\n",
      "100%|██████████████████████████████████████████████| 10/10 [02:43<00:00, 163.18s/trial, best loss: 0.08752136752136752]\n",
      "100%|███████████████████████████████████████████████| 11/11 [01:05<00:00, 65.50s/trial, best loss: 0.08752136752136752]\n",
      "100%|███████████████████████████████████████████████| 12/12 [00:07<00:00,  7.23s/trial, best loss: 0.08752136752136752]\n",
      "100%|███████████████████████████████████████████████| 13/13 [00:05<00:00,  5.77s/trial, best loss: 0.08752136752136752]\n",
      "100%|██████████████████████████████████████████████| 14/14 [03:44<00:00, 224.73s/trial, best loss: 0.08752136752136752]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:08<00:00,  8.22s/trial, best loss: 0.08752136752136752]\n",
      "100%|███████████████████████████████████████████████| 16/16 [00:34<00:00, 34.70s/trial, best loss: 0.08752136752136752]\n",
      "100%|███████████████████████████████████████████████| 17/17 [00:25<00:00, 25.38s/trial, best loss: 0.08752136752136752]\n",
      "100%|███████████████████████████████████████████████| 18/18 [01:26<00:00, 86.69s/trial, best loss: 0.08752136752136752]\n",
      "100%|███████████████████████████████████████████████| 19/19 [00:59<00:00, 59.87s/trial, best loss: 0.08752136752136752]\n",
      "100%|███████████████████████████████████████████████| 20/20 [00:30<00:00, 30.12s/trial, best loss: 0.08752136752136752]\n",
      "(0.9112820512820513, {'learner': AdaBoostClassifier(learning_rate=0.0007973450504227367, n_estimators=59,\n",
      "                   random_state=4), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** DT ********************\n",
      "100%|██████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/trial, best loss: 0.1332539682539683]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.74s/trial, best loss: 0.13313186813186817]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.74s/trial, best loss: 0.13313186813186817]\n",
      "100%|██████████████████████████████████████████████████| 4/4 [00:01<00:00,  1.58s/trial, best loss: 0.0843284493284493]\n",
      "100%|██████████████████████████████████████████████████| 5/5 [00:01<00:00,  1.70s/trial, best loss: 0.0843284493284493]\n",
      "100%|██████████████████████████████████████████████████| 6/6 [00:01<00:00,  1.72s/trial, best loss: 0.0843284493284493]\n",
      "100%|██████████████████████████████████████████████████| 7/7 [00:01<00:00,  1.75s/trial, best loss: 0.0843284493284493]\n",
      "100%|██████████████████████████████████████████████████| 8/8 [00:01<00:00,  1.67s/trial, best loss: 0.0843284493284493]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:01<00:00,  1.75s/trial, best loss: 0.08431013431013434]\n",
      "100%|███████████████████████████████████████████████| 10/10 [00:01<00:00,  1.53s/trial, best loss: 0.08431013431013434]\n",
      "100%|███████████████████████████████████████████████| 11/11 [00:01<00:00,  1.69s/trial, best loss: 0.08431013431013434]\n",
      "100%|███████████████████████████████████████████████| 12/12 [00:01<00:00,  1.75s/trial, best loss: 0.08429792429792426]\n",
      "100%|███████████████████████████████████████████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.08429792429792426]\n",
      "100%|███████████████████████████████████████████████| 14/14 [00:01<00:00,  1.75s/trial, best loss: 0.08429792429792426]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:01<00:00,  1.79s/trial, best loss: 0.08429792429792426]\n",
      "100%|███████████████████████████████████████████████| 16/16 [00:01<00:00,  1.67s/trial, best loss: 0.08429792429792426]\n",
      "100%|███████████████████████████████████████████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.08429792429792426]\n",
      "100%|███████████████████████████████████████████████| 18/18 [00:01<00:00,  1.79s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 19/19 [00:01<00:00,  1.65s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 20/20 [00:01<00:00,  1.63s/trial, best loss: 0.08425518925518927]\n",
      "(0.864, {'learner': DecisionTreeClassifier(criterion='entropy', min_samples_leaf=2,\n",
      "                       min_samples_split=8, random_state=3, splitter='random'), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** ET ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.73s/trial, best loss: 0.13318070818070815]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:03<00:00,  3.40s/trial, best loss: 0.13309523809523804]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [01:34<00:00, 94.39s/trial, best loss: 0.08435897435897433]\n",
      "100%|████████████████████████████████████████████████| 4/4 [03:12<00:00, 193.00s/trial, best loss: 0.08435897435897433]\n",
      "100%|████████████████████████████████████████████████| 5/5 [03:58<00:00, 238.03s/trial, best loss: 0.08435286935286934]\n",
      "100%|█████████████████████████████████████████████████| 6/6 [00:35<00:00, 35.93s/trial, best loss: 0.08435286935286934]\n",
      "100%|█████████████████████████████████████████████████| 7/7 [01:13<00:00, 73.69s/trial, best loss: 0.08435286935286934]\n",
      "100%|█████████████████████████████████████████████████| 8/8 [00:05<00:00,  5.61s/trial, best loss: 0.08435286935286934]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:02<00:00,  2.84s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 10/10 [01:33<00:00, 93.99s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 11/11 [00:40<00:00, 40.99s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 12/12 [00:02<00:00,  2.76s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 13/13 [00:03<00:00,  3.33s/trial, best loss: 0.08427960927960931]\n",
      "100%|██████████████████████████████████████████████| 14/14 [03:14<00:00, 194.92s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:02<00:00,  2.84s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 16/16 [00:17<00:00, 17.15s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 17/17 [00:12<00:00, 12.24s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 18/18 [00:24<00:00, 24.26s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 19/19 [00:15<00:00, 15.66s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 20/20 [00:11<00:00, 11.02s/trial, best loss: 0.08427960927960931]\n",
      "(0.8640830280830281, {'learner': ExtraTreesClassifier(bootstrap=True, criterion='entropy',\n",
      "                     max_features=0.3826823680920317, min_samples_leaf=2,\n",
      "                     n_estimators=23, n_jobs=-1, random_state=2, verbose=False), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** GNB ********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.69s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.80s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:02<00:00,  2.67s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [00:02<00:00,  2.54s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.52s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.52s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.25s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 8/8 [00:01<00:00,  1.69s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:01<00:00,  1.74s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 10/10 [00:01<00:00,  1.75s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 11/11 [00:01<00:00,  1.76s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 12/12 [00:01<00:00,  1.69s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 13/13 [00:01<00:00,  1.70s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 14/14 [00:01<00:00,  1.70s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:01<00:00,  1.68s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 16/16 [00:01<00:00,  1.69s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 17/17 [00:01<00:00,  1.70s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 18/18 [00:01<00:00,  1.71s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 19/19 [00:01<00:00,  1.66s/trial, best loss: 0.13454212454212455]\n",
      "100%|███████████████████████████████████████████████| 20/20 [00:01<00:00,  1.68s/trial, best loss: 0.13454212454212455]\n",
      "(0.8626324786324786, {'learner': GaussianNB(), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** GB ********************\n",
      "100%|████████████████████████████████████████████████| 1/1 [03:44<00:00, 224.52s/trial, best loss: 0.11398046398046402]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:10<00:00, 10.68s/trial, best loss: 0.08431623931623933]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:24<00:00, 24.87s/trial, best loss: 0.08431623931623933]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [00:25<00:00, 25.07s/trial, best loss: 0.08429181929181928]\n",
      "100%|████████████████████████████████████████████████| 5/5 [02:16<00:00, 136.06s/trial, best loss: 0.08429181929181928]\n",
      "100%|█████████████████████████████████████████████████| 6/6 [00:12<00:00, 12.40s/trial, best loss: 0.08429181929181928]\n",
      "100%|████████████████████████████████████████████████| 7/7 [03:25<00:00, 205.24s/trial, best loss: 0.08429181929181928]\n",
      "100%|████████████████████████████████████████████████| 8/8 [02:30<00:00, 150.10s/trial, best loss: 0.08425518925518927]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:17<00:00, 17.23s/trial, best loss: 0.08425518925518927]\n",
      "100%|██████████████████████████████████████████████| 10/10 [02:01<00:00, 121.32s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 11/11 [00:07<00:00,  7.77s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 12/12 [00:50<00:00, 50.35s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 13/13 [01:32<00:00, 92.59s/trial, best loss: 0.08425518925518927]\n",
      "100%|██████████████████████████████████████████████| 14/14 [05:01<00:00, 301.18s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:41<00:00, 41.45s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 16/16 [00:57<00:00, 57.23s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 17/17 [01:29<00:00, 89.12s/trial, best loss: 0.08425518925518927]\n",
      "100%|██████████████████████████████████████████████| 18/18 [03:30<00:00, 210.30s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 19/19 [01:35<00:00, 95.97s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 20/20 [00:46<00:00, 46.64s/trial, best loss: 0.08425518925518927]\n",
      "(0.9141245421245421, {'learner': GradientBoostingClassifier(learning_rate=0.019732665262921015,\n",
      "                           loss='exponential', max_depth=4,\n",
      "                           max_features=0.4796525919545166, n_estimators=428,\n",
      "                           random_state=4), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** KN ********************\n",
      "100%|███████████████████████████████████████████████████████████████████| 1/1 [05:01<00:00, 301.19s/trial, best loss=?]\n",
      "********** Could not fit KN. Reason: ''. **********\n",
      "\n",
      "******************** LSVC ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.37s/trial, best loss: 0.14652014652014655]\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:02<00:00,  2.22s/trial, best loss: 0.1332417582417582]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [05:01<00:00, 301.16s/trial, best loss: 0.1332417582417582]\n",
      "100%|██████████████████████████████████████████████████| 4/4 [01:30<00:00, 90.86s/trial, best loss: 0.1332417582417582]\n",
      "100%|██████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.26s/trial, best loss: 0.1332417582417582]\n",
      "100%|██████████████████████████████████████████████████| 6/6 [00:53<00:00, 53.86s/trial, best loss: 0.1332417582417582]\n",
      "100%|█████████████████████████████████████████████████| 7/7 [05:01<00:00, 301.19s/trial, best loss: 0.1332417582417582]\n",
      "100%|██████████████████████████████████████████████████| 8/8 [00:59<00:00, 59.03s/trial, best loss: 0.1332417582417582]\n",
      "100%|██████████████████████████████████████████████████| 9/9 [00:01<00:00,  1.91s/trial, best loss: 0.1332417582417582]\n",
      "100%|███████████████████████████████████████████████| 10/10 [05:01<00:00, 301.18s/trial, best loss: 0.1332417582417582]\n",
      "100%|███████████████████████████████████████████████| 11/11 [05:01<00:00, 301.16s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 12/12 [00:48<00:00, 48.30s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 13/13 [00:02<00:00,  2.42s/trial, best loss: 0.1332417582417582]\n",
      "100%|███████████████████████████████████████████████| 14/14 [05:01<00:00, 301.17s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 15/15 [00:01<00:00,  1.90s/trial, best loss: 0.1332417582417582]\n",
      "100%|███████████████████████████████████████████████| 16/16 [05:01<00:00, 301.16s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 17/17 [00:06<00:00,  6.49s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 18/18 [00:02<00:00,  2.28s/trial, best loss: 0.1332417582417582]\n",
      "100%|███████████████████████████████████████████████| 19/19 [05:01<00:00, 301.16s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 20/20 [01:25<00:00, 85.83s/trial, best loss: 0.1332417582417582]\n",
      "(0.8638095238095238, {'learner': LinearSVC(C=0.11112997993290162, intercept_scaling=0.8513170967908988,\n",
      "          loss='hinge', random_state=3, tol=0.003292008207495153,\n",
      "          verbose=False), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** LDA ********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:02<00:00,  2.83s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:02<00:00,  2.91s/trial, best loss: 0.13446886446886452]\n",
      "100%|██████████████████████████████████████████████████| 4/4 [00:02<00:00,  2.69s/trial, best loss: 0.1332539682539683]\n",
      "100%|██████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.63s/trial, best loss: 0.1332539682539683]\n",
      "100%|██████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.64s/trial, best loss: 0.1332539682539683]\n",
      "100%|██████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.64s/trial, best loss: 0.1332539682539683]\n",
      " 88%|██████████████████████████████████████████████████████████████████▌         | 7/8 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: The leading minor of order 24 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████▌         | 7/8 [00:02<?, ?trial/s, best loss=?]\n",
      "********** Could not fit LDA. Reason: 'The leading minor of order 24 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.'. **********\n",
      "\n",
      "******************** MNB ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.54s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.53s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.55s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [00:01<00:00,  1.54s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 5/5 [00:01<00:00,  1.54s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 6/6 [00:01<00:00,  1.56s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 7/7 [00:01<00:00,  1.51s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 8/8 [00:01<00:00,  1.54s/trial, best loss: 0.13446886446886452]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:01<00:00,  1.53s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 10/10 [00:01<00:00,  1.55s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 11/11 [00:01<00:00,  1.53s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 12/12 [00:01<00:00,  1.54s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 13/13 [00:01<00:00,  1.53s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 14/14 [00:01<00:00,  1.54s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:01<00:00,  1.52s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 16/16 [00:01<00:00,  1.54s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 17/17 [00:01<00:00,  1.53s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 18/18 [00:01<00:00,  1.66s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 19/19 [00:01<00:00,  1.53s/trial, best loss: 0.13446886446886452]\n",
      "100%|███████████████████████████████████████████████| 20/20 [00:01<00:00,  1.53s/trial, best loss: 0.13446886446886452]\n",
      "(0.8627448107448108, {'learner': MultinomialNB(alpha=0.38), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** OVO ********************\n",
      "100%|██████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.41s/trial, best loss: 0.1357448107448107]\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:05<00:00,  5.11s/trial, best loss: 0.1357448107448107]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [03:23<00:00, 203.57s/trial, best loss: 0.1357448107448107]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [01:22<00:00, 82.83s/trial, best loss: 0.13353479853479855]\n",
      "100%|████████████████████████████████████████████████| 5/5 [04:34<00:00, 274.15s/trial, best loss: 0.13353479853479855]\n",
      " 83%|███████████████████████████████████████████████████████████████▎            | 5/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Unable to cast Python instance to C++ type (compile in debug mode for details)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████▎            | 5/6 [00:03<?, ?trial/s, best loss=?]\n",
      "********** Could not fit OVO. Reason: 'Unable to cast Python instance to C++ type (compile in debug mode for details)'. **********\n",
      "\n",
      "******************** OVR ********************\n",
      "100%|██████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.41s/trial, best loss: 0.1357448107448107]\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:05<00:00,  5.20s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 3/3 [03:25<00:00, 205.55s/trial, best loss: 0.08438339438339437]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [01:14<00:00, 74.87s/trial, best loss: 0.08438339438339437]\n",
      "100%|████████████████████████████████████████████████| 5/5 [05:01<00:00, 301.18s/trial, best loss: 0.08438339438339437]\n",
      " 83%|███████████████████████████████████████████████████████████████▎            | 5/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Unable to cast Python instance to C++ type (compile in debug mode for details)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████▎            | 5/6 [00:05<?, ?trial/s, best loss=?]\n",
      "********** Could not fit OVR. Reason: 'Unable to cast Python instance to C++ type (compile in debug mode for details)'. **********\n",
      "\n",
      "******************** OC ********************\n",
      "100%|██████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.13s/trial, best loss: 0.1357448107448107]\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:05<00:00,  5.81s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 3/3 [04:12<00:00, 252.14s/trial, best loss: 0.08438339438339437]\n",
      "100%|████████████████████████████████████████████████| 4/4 [02:31<00:00, 151.48s/trial, best loss: 0.08438339438339437]\n",
      "100%|████████████████████████████████████████████████| 5/5 [05:01<00:00, 301.19s/trial, best loss: 0.08438339438339437]\n",
      " 83%|███████████████████████████████████████████████████████████████▎            | 5/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Unable to cast Python instance to C++ type (compile in debug mode for details)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████▎            | 5/6 [00:06<?, ?trial/s, best loss=?]\n",
      "********** Could not fit OC. Reason: 'Unable to cast Python instance to C++ type (compile in debug mode for details)'. **********\n",
      "\n",
      "******************** PA ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.56s/trial, best loss: 0.13323565323565323]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:02<00:00,  2.50s/trial, best loss: 0.13323565323565323]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:02<00:00,  2.58s/trial, best loss: 0.13323565323565323]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [00:02<00:00,  2.68s/trial, best loss: 0.13323565323565323]\n",
      "100%|█████████████████████████████████████████████████| 5/5 [00:03<00:00,  3.64s/trial, best loss: 0.13323565323565323]\n",
      "100%|█████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.57s/trial, best loss: 0.13323565323565323]\n",
      "100%|█████████████████████████████████████████████████| 7/7 [00:03<00:00,  3.91s/trial, best loss: 0.13323565323565323]\n",
      "100%|█████████████████████████████████████████████████| 8/8 [00:02<00:00,  2.56s/trial, best loss: 0.13323565323565323]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:02<00:00,  2.64s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 10/10 [00:02<00:00,  2.56s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 11/11 [00:03<00:00,  3.04s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 12/12 [00:02<00:00,  2.63s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 13/13 [00:02<00:00,  2.74s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 14/14 [00:02<00:00,  2.62s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:02<00:00,  2.46s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 16/16 [00:02<00:00,  2.56s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 17/17 [00:03<00:00,  3.43s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 18/18 [00:02<00:00,  2.53s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 19/19 [00:02<00:00,  2.66s/trial, best loss: 0.13323565323565323]\n",
      "100%|███████████████████████████████████████████████| 20/20 [00:02<00:00,  2.59s/trial, best loss: 0.13323565323565323]\n",
      "(0.8638144078144078, {'learner': PassiveAggressiveClassifier(C=0.10580618144023571, fit_intercept=False,\n",
      "                            max_iter=548676042.0, n_jobs=-1, random_state=3,\n",
      "                            tol=0.003799057710504326, verbose=False), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** QDA ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.30s/trial, best loss: 0.19168498168498171]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:02<00:00,  2.21s/trial, best loss: 0.19168498168498171]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:02<00:00,  2.27s/trial, best loss: 0.13937728937728933]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [00:02<00:00,  2.39s/trial, best loss: 0.13937728937728933]\n",
      "100%|██████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.28s/trial, best loss: 0.1357448107448107]\n",
      "100%|██████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.34s/trial, best loss: 0.1357448107448107]\n",
      "100%|██████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.41s/trial, best loss: 0.1357448107448107]\n",
      "100%|██████████████████████████████████████████████████| 8/8 [00:02<00:00,  2.32s/trial, best loss: 0.1357448107448107]\n",
      "100%|██████████████████████████████████████████████████| 9/9 [00:02<00:00,  2.32s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 10/10 [00:02<00:00,  2.39s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 11/11 [00:02<00:00,  2.39s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 12/12 [00:02<00:00,  2.33s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 13/13 [00:02<00:00,  2.36s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 14/14 [00:02<00:00,  2.34s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 15/15 [00:02<00:00,  2.32s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 16/16 [00:02<00:00,  2.38s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 17/17 [00:02<00:00,  2.34s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 18/18 [00:02<00:00,  2.46s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 19/19 [00:02<00:00,  2.37s/trial, best loss: 0.1357448107448107]\n",
      "100%|████████████████████████████████████████████████| 20/20 [00:02<00:00,  2.27s/trial, best loss: 0.1357448107448107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marce\\Anaconda2\\envs\\doutorado\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8617728937728938, {'learner': QuadraticDiscriminantAnalysis(reg_param=0.28192310047566127), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** RF ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.80s/trial, best loss: 0.08440781440781442]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:03<00:00,  3.90s/trial, best loss: 0.08429792429792426]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:56<00:00, 56.55s/trial, best loss: 0.08429792429792426]\n",
      "100%|████████████████████████████████████████████████| 4/4 [01:41<00:00, 101.73s/trial, best loss: 0.08429792429792426]\n",
      "100%|████████████████████████████████████████████████| 5/5 [05:01<00:00, 301.18s/trial, best loss: 0.08429792429792426]\n",
      "100%|█████████████████████████████████████████████████| 6/6 [00:58<00:00, 58.91s/trial, best loss: 0.08427960927960931]\n",
      "100%|█████████████████████████████████████████████████| 7/7 [00:43<00:00, 43.01s/trial, best loss: 0.08427960927960931]\n",
      "100%|█████████████████████████████████████████████████| 8/8 [00:07<00:00,  7.98s/trial, best loss: 0.08427960927960931]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:03<00:00,  3.27s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 10/10 [01:00<00:00, 60.22s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 11/11 [00:40<00:00, 40.96s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 12/12 [00:03<00:00,  3.25s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 13/13 [00:02<00:00,  2.50s/trial, best loss: 0.08427960927960931]\n",
      "100%|██████████████████████████████████████████████| 14/14 [03:13<00:00, 193.72s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:02<00:00,  2.44s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 16/16 [00:32<00:00, 32.72s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 17/17 [00:11<00:00, 11.71s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 18/18 [00:41<00:00, 41.76s/trial, best loss: 0.08427960927960931]\n",
      "100%|███████████████████████████████████████████████| 19/19 [00:21<00:00, 21.67s/trial, best loss: 0.08425518925518927]\n",
      "100%|███████████████████████████████████████████████| 20/20 [00:08<00:00,  8.25s/trial, best loss: 0.08425518925518927]\n",
      "(0.9141587301587302, {'learner': RandomForestClassifier(criterion='entropy', max_features='log2',\n",
      "                       min_samples_leaf=7, n_estimators=374, n_jobs=-1,\n",
      "                       random_state=4, verbose=False), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** SGD ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.52s/trial, best loss: 0.19168498168498171]\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:03<00:00,  3.35s/trial, best loss: 0.1357448107448107]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:05<00:00,  5.17s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [00:03<00:00,  3.08s/trial, best loss: 0.13454212454212455]\n",
      "100%|█████████████████████████████████████████████████| 5/5 [00:19<00:00, 19.17s/trial, best loss: 0.13330891330891326]\n",
      "100%|█████████████████████████████████████████████████| 6/6 [01:39<00:00, 99.78s/trial, best loss: 0.13330891330891326]\n",
      "100%|█████████████████████████████████████████████████| 7/7 [00:06<00:00,  6.79s/trial, best loss: 0.13330891330891326]\n",
      "100%|██████████████████████████████████████████████████| 8/8 [00:02<00:00,  2.38s/trial, best loss: 0.1332417582417582]\n",
      "100%|██████████████████████████████████████████████████| 9/9 [00:02<00:00,  2.19s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 10/10 [00:02<00:00,  2.56s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 11/11 [00:02<00:00,  2.50s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 12/12 [00:02<00:00,  2.16s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 13/13 [00:02<00:00,  2.81s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 14/14 [00:29<00:00, 29.46s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 15/15 [00:02<00:00,  2.35s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 16/16 [00:02<00:00,  2.79s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 17/17 [00:02<00:00,  2.94s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 18/18 [00:02<00:00,  2.24s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 19/19 [00:02<00:00,  2.37s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 20/20 [00:02<00:00,  2.18s/trial, best loss: 0.1332417582417582]\n",
      "(0.8637948717948718, {'learner': SGDClassifier(alpha=3.635544519065662e-05, eta0=0.08701776522406507,\n",
      "              l1_ratio=0.17548168634130723, learning_rate='constant',\n",
      "              loss='log', max_iter=300476604.0, n_jobs=-1, penalty='elasticnet',\n",
      "              power_t=0.8135731811888463, random_state=4,\n",
      "              tol=0.002726162070321745, verbose=False), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** SVC-LL ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [03:48<00:00, 228.30s/trial, best loss: 0.1334249084249084]\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:23<00:00, 23.51s/trial, best loss: 0.1334249084249084]\n",
      "100%|██████████████████████████████████████████████████| 3/3 [00:23<00:00, 23.66s/trial, best loss: 0.1334249084249084]\n",
      "100%|██████████████████████████████████████████████████| 4/4 [00:12<00:00, 12.05s/trial, best loss: 0.1334249084249084]\n",
      " 80%|████████████████████████████████████████████████████████████▊               | 4/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:hyperopt.fmin:job exception: Unable to cast Python instance to C++ type (compile in debug mode for details)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▊               | 4/5 [00:01<?, ?trial/s, best loss=?]\n",
      "********** Could not fit SVC-LL. Reason: 'Unable to cast Python instance to C++ type (compile in debug mode for details)'. **********\n",
      "\n",
      "******************** SVC-L ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.45s/trial, best loss: 0.14640415140415142]\n",
      "100%|██████████████████████████████████████████████████| 2/2 [00:11<00:00, 11.78s/trial, best loss: 0.1334188034188034]\n",
      "100%|██████████████████████████████████████████████████| 3/3 [00:12<00:00, 12.24s/trial, best loss: 0.1334188034188034]\n",
      "100%|████████████████████████████████████████████████| 4/4 [01:49<00:00, 109.62s/trial, best loss: 0.13340659340659344]\n",
      "100%|████████████████████████████████████████████████| 5/5 [02:08<00:00, 128.42s/trial, best loss: 0.13340659340659344]\n",
      "100%|█████████████████████████████████████████████████| 6/6 [00:11<00:00, 11.99s/trial, best loss: 0.13340659340659344]\n",
      "100%|████████████████████████████████████████████████| 7/7 [02:20<00:00, 140.91s/trial, best loss: 0.13336996336996332]\n",
      "100%|█████████████████████████████████████████████████| 8/8 [00:15<00:00, 15.68s/trial, best loss: 0.13336996336996332]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:12<00:00, 12.72s/trial, best loss: 0.13336996336996332]\n",
      "100%|██████████████████████████████████████████████| 10/10 [02:08<00:00, 128.90s/trial, best loss: 0.13336996336996332]\n",
      "100%|███████████████████████████████████████████████| 11/11 [00:11<00:00, 11.99s/trial, best loss: 0.13336996336996332]\n",
      "100%|██████████████████████████████████████████████| 12/12 [02:33<00:00, 153.82s/trial, best loss: 0.13336996336996332]\n",
      "100%|██████████████████████████████████████████████| 13/13 [01:55<00:00, 115.37s/trial, best loss: 0.13336996336996332]\n",
      "100%|██████████████████████████████████████████████| 14/14 [04:25<00:00, 265.51s/trial, best loss: 0.13336996336996332]\n",
      "100%|██████████████████████████████████████████████| 15/15 [01:50<00:00, 110.81s/trial, best loss: 0.13336996336996332]\n",
      "100%|███████████████████████████████████████████████| 16/16 [01:54<00:00, 114.13s/trial, best loss: 0.1332417582417582]\n",
      "100%|███████████████████████████████████████████████| 17/17 [01:45<00:00, 105.22s/trial, best loss: 0.1332417582417582]\n",
      "100%|███████████████████████████████████████████████| 18/18 [02:19<00:00, 139.42s/trial, best loss: 0.1332417582417582]\n",
      "100%|███████████████████████████████████████████████| 19/19 [02:03<00:00, 123.74s/trial, best loss: 0.1332417582417582]\n",
      "100%|████████████████████████████████████████████████| 20/20 [00:41<00:00, 41.50s/trial, best loss: 0.1332417582417582]\n",
      "(0.8636141636141637, {'learner': SVC(C=6.991759392024011, cache_size=512, degree=1, gamma='auto',\n",
      "    kernel='linear', max_iter=186430450.0, random_state=2,\n",
      "    tol=0.00896552219109305), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** SVC-P ********************\n",
      "  0%|                                                                            | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:hyperopt.fmin:job exception: Unable to cast Python instance to C++ type (compile in debug mode for details)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/1 [00:01<?, ?trial/s, best loss=?]\n",
      "********** Could not fit SVC-P. Reason: 'Unable to cast Python instance to C++ type (compile in debug mode for details)'. **********\n",
      "\n",
      "******************** SVC-R ********************\n",
      "100%|████████████████████████████████████████████████| 1/1 [01:51<00:00, 111.96s/trial, best loss: 0.13343101343101338]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:13<00:00, 13.63s/trial, best loss: 0.13343101343101338]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [03:12<00:00, 192.33s/trial, best loss: 0.1332905982905983]\n",
      "100%|██████████████████████████████████████████████████| 4/4 [00:12<00:00, 12.56s/trial, best loss: 0.1332905982905983]\n",
      "100%|██████████████████████████████████████████████████| 5/5 [01:31<00:00, 91.64s/trial, best loss: 0.1332905982905983]\n",
      "100%|██████████████████████████████████████████████████| 6/6 [00:12<00:00, 12.38s/trial, best loss: 0.1332905982905983]\n",
      "100%|█████████████████████████████████████████████████| 7/7 [02:00<00:00, 120.11s/trial, best loss: 0.1332905982905983]\n",
      "100%|██████████████████████████████████████████████████| 8/8 [01:19<00:00, 79.02s/trial, best loss: 0.1332905982905983]\n",
      "100%|██████████████████████████████████████████████████| 9/9 [00:12<00:00, 12.20s/trial, best loss: 0.1332905982905983]\n",
      "100%|████████████████████████████████████████████████| 10/10 [00:42<00:00, 42.49s/trial, best loss: 0.1332905982905983]\n",
      "100%|██████████████████████████████████████████████| 11/11 [01:50<00:00, 110.06s/trial, best loss: 0.11988400488400486]\n",
      "100%|██████████████████████████████████████████████| 12/12 [01:50<00:00, 110.71s/trial, best loss: 0.11988400488400486]\n",
      "100%|███████████████████████████████████████████████| 13/13 [00:43<00:00, 43.83s/trial, best loss: 0.11988400488400486]\n",
      "100%|██████████████████████████████████████████████| 14/14 [01:44<00:00, 104.76s/trial, best loss: 0.11988400488400486]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:12<00:00, 12.23s/trial, best loss: 0.11988400488400486]\n",
      "100%|███████████████████████████████████████████████| 16/16 [01:11<00:00, 71.25s/trial, best loss: 0.11988400488400486]\n",
      "100%|██████████████████████████████████████████████| 17/17 [01:54<00:00, 114.95s/trial, best loss: 0.11988400488400486]\n",
      "100%|███████████████████████████████████████████████| 18/18 [00:12<00:00, 12.17s/trial, best loss: 0.11988400488400486]\n",
      "100%|██████████████████████████████████████████████| 19/19 [02:08<00:00, 128.34s/trial, best loss: 0.11988400488400486]\n",
      "100%|██████████████████████████████████████████████| 20/20 [01:52<00:00, 112.85s/trial, best loss: 0.11988400488400486]\n",
      "(0.8534310134310135, {'learner': SVC(C=4.748605227189839, cache_size=512, degree=1, gamma=0.009444372150077604,\n",
      "    max_iter=432657198.0, random_state=3, tol=7.933853944091779e-05), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** SVC-S ********************\n",
      "100%|█████████████████████████████████████████████████| 1/1 [00:22<00:00, 22.70s/trial, best loss: 0.14656898656898654]\n",
      "100%|█████████████████████████████████████████████████| 2/2 [00:24<00:00, 25.00s/trial, best loss: 0.14656898656898654]\n",
      "100%|█████████████████████████████████████████████████| 3/3 [00:14<00:00, 14.55s/trial, best loss: 0.14656898656898654]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [00:23<00:00, 23.54s/trial, best loss: 0.14656898656898654]\n",
      "100%|████████████████████████████████████████████████| 5/5 [02:37<00:00, 157.40s/trial, best loss: 0.13349206349206344]\n",
      "100%|████████████████████████████████████████████████| 6/6 [03:57<00:00, 237.09s/trial, best loss: 0.13349206349206344]\n",
      "100%|████████████████████████████████████████████████| 7/7 [02:15<00:00, 135.38s/trial, best loss: 0.13349206349206344]\n",
      "100%|█████████████████████████████████████████████████| 8/8 [00:14<00:00, 14.69s/trial, best loss: 0.13349206349206344]\n",
      "100%|█████████████████████████████████████████████████| 9/9 [00:23<00:00, 23.28s/trial, best loss: 0.13349206349206344]\n",
      "100%|███████████████████████████████████████████████| 10/10 [00:23<00:00, 23.02s/trial, best loss: 0.13349206349206344]\n",
      "100%|███████████████████████████████████████████████| 11/11 [00:14<00:00, 14.64s/trial, best loss: 0.13349206349206344]\n",
      "100%|███████████████████████████████████████████████| 12/12 [00:23<00:00, 23.59s/trial, best loss: 0.13349206349206344]\n",
      "100%|██████████████████████████████████████████████| 13/13 [02:16<00:00, 136.66s/trial, best loss: 0.13349206349206344]\n",
      "100%|██████████████████████████████████████████████| 14/14 [02:15<00:00, 135.77s/trial, best loss: 0.13349206349206344]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:23<00:00, 23.68s/trial, best loss: 0.13349206349206344]\n",
      "100%|███████████████████████████████████████████████| 16/16 [00:14<00:00, 14.65s/trial, best loss: 0.13349206349206344]\n",
      "100%|███████████████████████████████████████████████| 17/17 [00:23<00:00, 23.59s/trial, best loss: 0.13349206349206344]\n",
      "100%|███████████████████████████████████████████████| 18/18 [00:23<00:00, 23.88s/trial, best loss: 0.13349206349206344]\n",
      "100%|███████████████████████████████████████████████| 19/19 [00:14<00:00, 14.58s/trial, best loss: 0.13349206349206344]\n",
      "100%|███████████████████████████████████████████████| 20/20 [00:14<00:00, 14.44s/trial, best loss: 0.13349206349206344]\n",
      "(0.8636092796092796, {'learner': SVC(C=1308.5659152504284, cache_size=512, coef0=0, degree=1,\n",
      "    gamma=0.020114878493420366, kernel='sigmoid', max_iter=13085973.0,\n",
      "    random_state=4, tol=7.010827821439637e-05), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "\n",
      "******************** XGB ********************\n",
      "100%|████████████████████████████████████████████████| 1/1 [02:51<00:00, 171.66s/trial, best loss: 0.08426129426129425]\n",
      "100%|████████████████████████████████████████████████| 2/2 [01:54<00:00, 114.16s/trial, best loss: 0.08426129426129425]\n",
      "100%|████████████████████████████████████████████████| 3/3 [03:28<00:00, 208.42s/trial, best loss: 0.08426129426129425]\n",
      "100%|█████████████████████████████████████████████████| 4/4 [01:24<00:00, 84.69s/trial, best loss: 0.08426129426129425]\n",
      "100%|█████████████████████████████████████████████████| 5/5 [01:30<00:00, 90.53s/trial, best loss: 0.08426129426129425]\n",
      "100%|████████████████████████████████████████████████| 6/6 [02:45<00:00, 165.38s/trial, best loss: 0.08426129426129425]\n",
      "100%|████████████████████████████████████████████████| 7/7 [04:10<00:00, 250.21s/trial, best loss: 0.08426129426129425]\n",
      "100%|████████████████████████████████████████████████| 8/8 [03:04<00:00, 184.69s/trial, best loss: 0.08426129426129425]\n",
      "100%|████████████████████████████████████████████████| 9/9 [01:41<00:00, 101.90s/trial, best loss: 0.08426129426129425]\n",
      "100%|██████████████████████████████████████████████| 10/10 [03:20<00:00, 200.24s/trial, best loss: 0.08426129426129425]\n",
      "100%|██████████████████████████████████████████████| 11/11 [02:55<00:00, 175.98s/trial, best loss: 0.08426129426129425]\n",
      "100%|██████████████████████████████████████████████| 12/12 [03:03<00:00, 183.78s/trial, best loss: 0.08426129426129425]\n",
      "100%|██████████████████████████████████████████████| 13/13 [03:12<00:00, 192.02s/trial, best loss: 0.08426129426129425]\n",
      "100%|██████████████████████████████████████████████| 14/14 [03:27<00:00, 207.91s/trial, best loss: 0.08426129426129425]\n",
      "100%|███████████████████████████████████████████████| 15/15 [00:08<00:00,  8.88s/trial, best loss: 0.08426129426129425]\n",
      "100%|██████████████████████████████████████████████| 16/16 [04:03<00:00, 243.65s/trial, best loss: 0.08426129426129425]\n",
      "100%|██████████████████████████████████████████████| 17/17 [03:40<00:00, 220.17s/trial, best loss: 0.08426129426129425]\n",
      "100%|███████████████████████████████████████████████| 18/18 [00:09<00:00,  9.09s/trial, best loss: 0.08426129426129425]\n",
      "100%|██████████████████████████████████████████████| 19/19 [05:01<00:00, 301.56s/trial, best loss: 0.08426129426129425]\n",
      "100%|██████████████████████████████████████████████| 20/20 [04:19<00:00, 259.36s/trial, best loss: 0.08426129426129425]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marce\\Anaconda2\\envs\\doutorado\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:35:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0.9142026862026862, {'learner': XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              colsample_bylevel=0.5701541246097266, colsample_bynode=1,\n",
      "              colsample_bytree=0.7470728059084097, enable_categorical=False,\n",
      "              gamma=3.496245955670253e-05, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.02687981851587668,\n",
      "              max_delta_step=0, max_depth=3, min_child_weight=6, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=3800, n_jobs=-1,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=3,\n",
      "              reg_alpha=0.0020203335588819434, reg_lambda=3.3387683435131232,\n",
      "              scale_pos_weight=1, seed=3, subsample=0.9299459818100199,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None), 'preprocs': (MinMaxScaler(),), 'ex_preprocs': ()})\n",
      "****************************************\n",
      "**** Fit success rate: 15/22 ****\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "best_results = {}\n",
    "\n",
    "success = 0\n",
    "\n",
    "classifiers = [\n",
    "    ada_boost('ab'),\n",
    "    decision_tree('dt'),\n",
    "    extra_trees('et'),\n",
    "    gaussian_nb('gnb'),\n",
    "    gradient_boosting('gb'),\n",
    "    knn('knn'),\n",
    "    liblinear_svc('svc-ll'),\n",
    "    linear_discriminant_analysis('lda',n_components=1),\n",
    "    multinomial_nb('mnb'),\n",
    "    one_vs_one('ovo'),\n",
    "    one_vs_rest('ovr'),\n",
    "    output_code('oc'),\n",
    "    passive_aggressive('pa'),\n",
    "    quadratic_discriminant_analysis('qda'),\n",
    "    random_forest('rf'),\n",
    "    sgd('sgd'),\n",
    "    svc('svc'),\n",
    "    svc_linear('svc-l'),\n",
    "    svc_poly('svc-p'),\n",
    "    svc_rbf('svc-r'),\n",
    "    svc_sigmoid('svc-s'),\n",
    "    xgboost_classification('xgb')\n",
    "]\n",
    "\n",
    "for clf in classifiers:\n",
    "    \n",
    "    clf_name = clf.name.replace('sklearn_','').replace('Classifier','')\n",
    "    if clf_name == 'switch':\n",
    "        clf_name = 'SVC-LL'\n",
    "    elif 'SVC' in clf_name:\n",
    "        for arg in clf.named_args:\n",
    "            if arg[0] == 'kernel':\n",
    "                clf_name += f'-{arg[1].obj.capitalize()[0]}'\n",
    "    clf_name = ''.join(c for c in clf_name if (c.isupper() or c == '-'))\n",
    "    \n",
    "    print(f'\\n******************** {clf_name} ********************')\n",
    "    \n",
    "    try:\n",
    "            \n",
    "        estim = HyperoptEstimator(classifier=clf,\n",
    "                                  preprocessing=[min_max_scaler('my_pre',feature_range=(0,1))],\n",
    "                                  algo=tpe.suggest,\n",
    "                                  max_evals=20,\n",
    "                                  trial_timeout=300,\n",
    "                                  seed=np.random.default_rng(SEED),\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "        estim.fit(X_train, Y_train, random_state=SEED)\n",
    "\n",
    "        score = estim.score(X_test, Y_test)\n",
    "        \n",
    "        best_model = estim.best_model()\n",
    "    \n",
    "        best_results[clf_name] = (score, best_model)\n",
    "        print(best_results[clf_name])\n",
    "        \n",
    "        success += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"********** Could not fit {clf_name}. Reason: '{str(e)}'. **********\")\n",
    "        best_results[clf_name] = (0.0, None)\n",
    "\n",
    "print(f'****************************************')\n",
    "print(f'**** Fit success rate: {success}/{len(classifiers)} ****')\n",
    "print(f'****************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c21cceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"AB\": [\n",
      "        0.9112820512820513,\n",
      "        {\n",
      "            \"learner\": \"AdaBoostClassifier(learning_rate=0.0007973450504227367, n_estimators=59,\\n                   random_state=4)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"DT\": [\n",
      "        0.864,\n",
      "        {\n",
      "            \"learner\": \"DecisionTreeClassifier(criterion='entropy', min_samples_leaf=2,\\n                       min_samples_split=8, random_state=3, splitter='random')\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"ET\": [\n",
      "        0.8640830280830281,\n",
      "        {\n",
      "            \"learner\": \"ExtraTreesClassifier(bootstrap=True, criterion='entropy',\\n                     max_features=0.3826823680920317, min_samples_leaf=2,\\n                     n_estimators=23, n_jobs=-1, random_state=2, verbose=False)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"GB\": [\n",
      "        0.9141245421245421,\n",
      "        {\n",
      "            \"learner\": \"GradientBoostingClassifier(learning_rate=0.019732665262921015,\\n                           loss='exponential', max_depth=4,\\n                           max_features=0.4796525919545166, n_estimators=428,\\n                           random_state=4)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"GNB\": [\n",
      "        0.8626324786324786,\n",
      "        {\n",
      "            \"learner\": \"GaussianNB()\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"KN\": [\n",
      "        0.0,\n",
      "        null\n",
      "    ],\n",
      "    \"LDA\": [\n",
      "        0.0,\n",
      "        null\n",
      "    ],\n",
      "    \"LSVC\": [\n",
      "        0.8638095238095238,\n",
      "        {\n",
      "            \"learner\": \"LinearSVC(C=0.11112997993290162, intercept_scaling=0.8513170967908988,\\n          loss='hinge', random_state=3, tol=0.003292008207495153,\\n          verbose=False)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"MNB\": [\n",
      "        0.8627448107448108,\n",
      "        {\n",
      "            \"learner\": \"MultinomialNB(alpha=0.38)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"OC\": [\n",
      "        0.0,\n",
      "        null\n",
      "    ],\n",
      "    \"OVO\": [\n",
      "        0.0,\n",
      "        null\n",
      "    ],\n",
      "    \"OVR\": [\n",
      "        0.0,\n",
      "        null\n",
      "    ],\n",
      "    \"PA\": [\n",
      "        0.8638144078144078,\n",
      "        {\n",
      "            \"learner\": \"PassiveAggressiveClassifier(C=0.10580618144023571, fit_intercept=False,\\n                            max_iter=548676042.0, n_jobs=-1, random_state=3,\\n                            tol=0.003799057710504326, verbose=False)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"QDA\": [\n",
      "        0.8617728937728938,\n",
      "        {\n",
      "            \"learner\": \"QuadraticDiscriminantAnalysis(reg_param=0.28192310047566127)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"RF\": [\n",
      "        0.9141587301587302,\n",
      "        {\n",
      "            \"learner\": \"RandomForestClassifier(criterion='entropy', max_features='log2',\\n                       min_samples_leaf=7, n_estimators=374, n_jobs=-1,\\n                       random_state=4, verbose=False)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"SGD\": [\n",
      "        0.8637948717948718,\n",
      "        {\n",
      "            \"learner\": \"SGDClassifier(alpha=3.635544519065662e-05, eta0=0.08701776522406507,\\n              l1_ratio=0.17548168634130723, learning_rate='constant',\\n              loss='log', max_iter=300476604.0, n_jobs=-1, penalty='elasticnet',\\n              power_t=0.8135731811888463, random_state=4,\\n              tol=0.002726162070321745, verbose=False)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"SVC-L\": [\n",
      "        0.8636141636141637,\n",
      "        {\n",
      "            \"learner\": \"SVC(C=6.991759392024011, cache_size=512, degree=1, gamma='auto',\\n    kernel='linear', max_iter=186430450.0, random_state=2,\\n    tol=0.00896552219109305)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"SVC-LL\": [\n",
      "        0.0,\n",
      "        null\n",
      "    ],\n",
      "    \"SVC-P\": [\n",
      "        0.0,\n",
      "        null\n",
      "    ],\n",
      "    \"SVC-R\": [\n",
      "        0.8534310134310135,\n",
      "        {\n",
      "            \"learner\": \"SVC(C=4.748605227189839, cache_size=512, degree=1, gamma=0.009444372150077604,\\n    max_iter=432657198.0, random_state=3, tol=7.933853944091779e-05)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"SVC-S\": [\n",
      "        0.8636092796092796,\n",
      "        {\n",
      "            \"learner\": \"SVC(C=1308.5659152504284, cache_size=512, coef0=0, degree=1,\\n    gamma=0.020114878493420366, kernel='sigmoid', max_iter=13085973.0,\\n    random_state=4, tol=7.010827821439637e-05)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ],\n",
      "    \"XGB\": [\n",
      "        0.9142026862026862,\n",
      "        {\n",
      "            \"learner\": \"XGBClassifier(base_score=0.5, booster='gbtree',\\n              colsample_bylevel=0.5701541246097266, colsample_bynode=1,\\n              colsample_bytree=0.7470728059084097, enable_categorical=False,\\n              gamma=3.496245955670253e-05, gpu_id=-1, importance_type=None,\\n              interaction_constraints='', learning_rate=0.02687981851587668,\\n              max_delta_step=0, max_depth=3, min_child_weight=6, missing=nan,\\n              monotone_constraints='()', n_estimators=3800, n_jobs=-1,\\n              num_parallel_tree=1, predictor='auto', random_state=3,\\n              reg_alpha=0.0020203335588819434, reg_lambda=3.3387683435131232,\\n              scale_pos_weight=1, seed=3, subsample=0.9299459818100199,\\n              tree_method='exact', validate_parameters=1, verbosity=None)\",\n",
      "            \"preprocs\": [\n",
      "                \"MinMaxScaler()\"\n",
      "            ],\n",
      "            \"ex_preprocs\": []\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "best_results = dict(sorted(best_results.items()))\n",
    "print(json.dumps(best_results, indent=4, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1447725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 'DT', 'ET', 'GB', 'GNB', 'KN', 'LDA', 'LSVC', 'MNB', 'OC', 'OVO', 'OVR', 'PA', 'QDA', 'RF', 'SGD', 'SVC-L', 'SVC-LL', 'SVC-P', 'SVC-R', 'SVC-S', 'XGB']\n",
      "[0.9112820512820513, 0.864, 0.8640830280830281, 0.9141245421245421, 0.8626324786324786, 0.0, 0.0, 0.8638095238095238, 0.8627448107448108, 0.0, 0.0, 0.0, 0.8638144078144078, 0.8617728937728938, 0.9141587301587302, 0.8637948717948718, 0.8636141636141637, 0.0, 0.0, 0.8534310134310135, 0.8636092796092796, 0.9142026862026862]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1692x594 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = list(best_results.keys())\n",
    "names[0] = 'SVC'\n",
    "print(names)\n",
    "values = list(x[0] for x in best_results.values())\n",
    "print(values)\n",
    "\n",
    "plt.figure(figsize=(23.5,8.25))\n",
    "idx = 0\n",
    "for i in range(len(best_results.keys())):\n",
    "    plt.bar(names[i],values[i])\n",
    "    plt.text(idx-0.3,values[i]+0.01,f'{100*values[i]:.1f}%')\n",
    "    idx += 1\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xticks(range(0,len(best_results)),names)\n",
    "plt.yticks(np.linspace(0,1,11))\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd064505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution finished at 2022-02-22 08:39:02.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution finished at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "IoT23 - DNN Opt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
